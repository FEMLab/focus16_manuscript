---
title: "Benchmarking Analysis: Extreme dataset"
author: "Benjamin Callahan"
date: "April 6, 2016"
output: html_document
editor_options: 
  chunk_output_type: console
---

This document records the benchmarking analysis of the Extreme dataset for our manuscript "DADA2: High resolution sample inference from Illumina amplicon data". Extreme is an Illumina Miseq 2x250 amplicon sequencing dataset generated from a mock community for this manuscript, and is available for download  [here](http://www.ncbi.nlm.nih.gov/sra/SRX1478507).

As several sample inference methods are being compared, many of the commands necessary to completely reproduce this analysis must be performed outside of R after downloading the necessary software. To make it easier for others to explore our results, we have provided a zip-file alongside this Rmd that contains the needed output of these outside-of-R methods. The results shown here can be completely reproduced by unzipping that file, downloading the sample fastqs from the above link and placing them in the unzipped directory, and then running the copy of this script in the unzipped directory (after changing the necessary paths).

Load the dada2 library and extras:
```{r, message=FALSE, warning=FALSE}
library(dada2); packageVersion("dada2")
library(ShortRead); packageVersion("ShortRead")
library(ggplot2); packageVersion("ggplot2")
load("./extremes.RData")
#setwd("~/Desktop/Extreme_Final/") # CHANGE ME to location of file
fnF <- "SRR2990088_1.fastq.gz"
fnR <- "SRR2990088_2.fastq.gz"
```

## Quality Filter and Trim

```{r}
plotQualityProfile(fnF)
```

Forward reads are reasonably high quality. Trimming the first 20 nts, and last 10 (truncate at 240).

```{r}
plotQualityProfile(fnR)
```

Reverse read quality drops off substantially. Trimming the first 20 nts, and last 50 (truncate at 200).

```{r}
filtF <- "ExtremeF_EE2.fastq.gz"
filtFO <- "ExtremeFO_EE2.fastq.gz"
filtR <- "ExtremeR_EE2.fastq.gz"
fastqPairedFilter(c(fnF, fnR), c(filtF, filtR), maxN=0, maxEE=2, truncQ=2, truncLen=c(240,200), trimLeft=c(20,20), compress=TRUE, verbose=TRUE)
fastqFilter(fnF, filtFO, maxN=0, maxEE=2, truncQ=2, truncLen=240, trimLeft=20, compress=TRUE, verbose=TRUE)
```

Kept about 60 percent of the paired reads and 70 percent of the forward-only reads.

## Run DADA2 Pipeline

Dereplicate:
```{r}
derepF <- derepFastq(filtF, verbose=TRUE)
derepFO <- derepFastq(filtFO, verbose=TRUE)
derepR <- derepFastq(filtR, verbose=TRUE)
```

Run dada algorithm:
```{r}
dadaF <- dada(derepF, err=inflateErr(tperr1, 3), selfConsist = TRUE, OMEGA_A=1e-40)
dadaR <- dada(derepR, err=inflateErr(tperr1, 3), selfConsist = TRUE, OMEGA_A=1e-40)
```


Merge paired reads:
```{r}
merger <- mergePairs(dadaF, derepF, dadaR, derepR, verbose=TRUE)
```

Remove chimeras:
```{r}
seqtab <- makeSequenceTable(merger)

hist(nchar(colnames(seqtab)))
seqtab.nochim <- removeBimeraDenovo(seqtab, method="consensus", multithread=TRUE, verbose=TRUE)
sum(seqtab.nochim)/sum(seqtab)
dim(seqtab.nochim)

taxa <- assignTaxonomy(seqtab.nochim, "~/Downloads/silva_nr_v132_train_set.fa.gz", multithread=TRUE)
taxa_silva <- assignSpecies(taxa, "~/Downloads/silva_species_assignment_v132.fa.gz", allowMultiple = T)

```


```{bash}
 cat ./results/2019-10-18-extremes-genus-focusdb/*.fasta > ./docs/extremes_combined.fasta
 cat ~/Downloads/silva_species_assignment_v132.fa >> ./docs/extremes_combined.fasta
```

```{r}
taxa_both <- assignSpecies(taxa, "./docs/extremes_combined.fasta", allowMultiple = T)
rownames(taxa_both) <- NULL
rownames(taxa_silva) <- NULL
table(is.na(taxa_silva[,1]))
table(is.na(taxa_both[,1]))
View(taxa_both)
save.image('extremes.RData')
```





###########################################################################
Note that most of the commands for these other pipelines must be run outside of R. These commands, to be executed in the shell after installing the relevant piece of software, are indicated by being preceded by #:

UPARSE (as implemented in [usearch version 8.1.1831](http://www.drive5.com/usearch/download.html)):
```{r}
#: mkdir up

#: usearch -derep_fulllength ExtremeFO_EE2.fastq -fastaout ExtremeFO_uniques.fasta -sizeout
#: usearch -sortbysize ExtremeFO_uniques.fasta -fastaout ExtremeFO_uniques_noS.fasta -minsize 2
#: usearch -cluster_otus ExtremeFO_uniques_noS.fasta -otus up/otusFO.fa -uparseout up/outFO.up -relabel UPFO_ -sizein -sizeout
#: usearch -usearch_global ExtremeM_uniques.fasta -db up/otusFO.fa -strand plus -id 0.97 -otutabout up/otutabFO.txt

#: usearch8.0.1517 -fastq_mergepairs ExtremeF_EE2.fastq -reverse ExtremeR_EE2.fastq -fastqout Extreme_merged.fastq -fastq_minovlen 20 -fastq_maxdiffs 1
#### Many apologies for introducing a second version of usearch, however a new default behavior for trimming
#### staggered alignments was introduced between this version of usearch and the current one, without any option
#### to revert to the previous behavior.
#: usearch -derep_fulllength Extreme_merged.fastq -fastaout ExtremeM_uniques.fasta -sizeout
#: usearch -sortbysize ExtremeM_uniques.fasta -fastaout ExtremeM_uniques_noS.fasta -minsize 2
#: usearch -cluster_otus ExtremeM_uniques_noS.fasta -otus up/otusM.fa -uparseout up/outM.up -relabel UPM_ -sizein -sizeout
#: usearch -usearch_global ExtremeM_uniques.fasta -db up/otusM.fa -strand plus -id 0.97 -otutabout up/otutabM.txt

ufo <- read.table("up/otutabFO.txt", colClasses = c("character", "numeric"), col.names=c("otu", "abundance"))
abunds <- as.integer(ufo$abundance)
names(abunds) <- ufo$otu
upseqsFO <- readFasta("up/otusFO.fa")
otus <- as.character(id(upseqsFO))
otus <- sapply(strsplit(otus,";"), `[`, 1)
upFO <- data.frame(sequence=as.character(sread(upseqsFO)), abundance=abunds[otus])

um <- read.table("up/otutabM.txt", colClasses = c("character", "numeric"), col.names=c("otu", "abundance"))
abunds <- as.integer(um$abundance)
names(abunds) <- um$otu
upseqsM <- readFasta("up/otusM.fa")
otus <- as.character(id(upseqsM))
otus <- sapply(strsplit(otus,";"), `[`, 1)
upM <- data.frame(sequence=as.character(sread(upseqsM)), abundance=abunds[otus])
```

MED (as implemented in [the oligotyping pipeline](http://merenlab.org/2014/08/16/installing-the-oligotyping-pipeline/) version 2.0):
```{r}
#: mkdir med
#: usearch -fastq_filter Extreme_merged.fastq -fastq_trunclen 220 -fastqout med/Extreme_merged_trimmed.fastq

#### Uncomment the following to create the MED formatted fasta file
# f <- FastqStreamer(filtFO, 1e7)
# fq <- yield(f)
# medids <- paste0("Sample-01_Read", seq(length(fq)))
# writeFasta(ShortRead(sread(fq), BStringSet(medids)), "med/medFO.fasta", width=20000)
# close(f)
# f <- FastqStreamer("med/Extreme_merged_trimmed.fastq", 1e7)
# fq <- yield(f)
# medids <- paste0("Sample-01_Read", seq(length(fq)))
# writeFasta(ShortRead(sread(fq), BStringSet(medids)), "med/medM.fasta", width=20000)
# close(f)
####

#: decompose -o med/medFO --skip-check-input med/medFO.fasta
#: decompose -o med/medM --skip-check-input med/medM.fasta

medseqsFO <- readFasta("med/medFO/NODE-REPRESENTATIVES.fasta")
medFO <- data.frame(sequence=as.character(sread(medseqsFO)), abundance=as.integer(as.character(subseq(id(medseqsFO), 16))))
bimFO.med <- isBimeraDenovo(medFO)
medFO <- medFO[!bimFO.med,]

medseqsM <- readFasta("med/medM/NODE-REPRESENTATIVES.fasta")
medM <- data.frame(sequence=as.character(sread(medseqsM)), abundance=as.integer(as.character(subseq(id(medseqsM), 16))))
bimM.med <- isBimeraDenovo(medM)
medM <- medM[!bimM.med,]
```

Average-linkage clustering (as implemented in [mothur](http://www.mothur.org/wiki/Download_mothur) version 1.36.1):
```{r}
#### Execute the following within the mothur environment
#: pcr.seqs(fasta=silva.bacteria.fasta, start=11894, end=25319, keepdots=F, processors=8)
#: make.contigs(file=ExtremeM.files, processors=8)
#: screen.seqs(fasta=current, group=current, maxambig=0, maxlength=275, maxhomop=8)
#: unique.seqs()
#: count.seqs(name=current, group=current)
#: align.seqs(fasta=current, reference=silva.bacteria.pcr.fasta)
#: summary.seqs(fasta=current)
#: screen.seqs(fasta=current, count=current, start=3063, end=10676)
#: filter.seqs(fasta=current, vertical=T, trump=.)
#: count.seqs(name=current, group=current)
#: unique.seqs(fasta=current, count=current)
#: pre.cluster(fasta=current, count=current, diffs=2)
#: chimera.uchime(fasta=current, count=current, dereplicate=T)
#: remove.seqs(fasta=current, accnos=current)
#: summary.seqs(fasta=current, count=current)
#: dist.seqs(fasta=current, cutoff=0.20)
#: cluster(column=current, count=current)
#: make.shared(list=current, count=current, label=0.03)
#: get.oturep(column=current, count=current, list=current, fasta=current, label=0.03)

#### FORWARD READ FILE FAILS TO COMPLETE DUE TO LARGE STORAGE REQUIREMENTS
#### Execute the following within the mothur environment
#: pcr.seqs(fasta=silva.bacteria.fasta, start=11894, end=25319, keepdots=F, processors=8)
#: fastq.info(fastq=ExtremeFO_EE2.fastq, format=illumina1.8+)
#: make.group(fasta=current, groups=ExtremeFO)
#: unique.seqs()
#: count.seqs(name=current, group=current)
#: align.seqs(fasta=current, reference=silva.bacteria.pcr.fasta)
#: summary.seqs(fasta=current)
#: screen.seqs(fasta=current, count=current, start=3063, end=10676)
#: filter.seqs(fasta=current, vertical=T, trump=.)
#: count.seqs(name=current, group=current)
#: unique.seqs(fasta=current, count=current)
#: pre.cluster(fasta=current, count=current, diffs=2)
#: chimera.uchime(fasta=current, count=current, dereplicate=T)
#: remove.seqs(fasta=current, accnos=current)
#: summary.seqs(fasta=current, count=current)
#: dist.seqs(fasta=current, cutoff=0.20)
#: cluster(column=current, count=current)
#: make.shared(list=current, count=current, label=0.03)
#: get.oturep(column=current, count=current, list=current, fasta=current, label=0.03)

mothseqsM <- readFasta("mothur/ExtremeM.trim.contigs.good.unique.good.filter.unique.precluster.pick.an.unique_list.0.03.rep.fasta")
abunds <- as.character(id(mothseqsM))
abunds <- sapply(strsplit(abunds,"\\t"), `[`, 2)
abunds <- sapply(strsplit(abunds,"\\|"), `[`, 2)
abunds <- as.integer(abunds)
mothM <- data.frame(sequence=as.character(sread(mothseqsM)), abundance = abunds)
mothM$sequence <- gsub("-", "", mothM$sequence)

mothFO <- data.frame(sequence=character(0), abundance=integer(0))
```

QIIME/uclust (as implemented in [MacQIIME](http://www.wernerlab.org/software/macqiime) version 1.9.1-20150604):
```{r}
#: usearch -fastq_filter ExtremeFO_EE2.fastq -fastaout ExtremeFO_EE2.fasta -fastq_ascii 64
#: usearch -fastq_filter Extreme_merged.fastq -fastaout Extreme_merged.fasta -fastq_ascii 64

#### Execute the following within the QIIME environment
#: identify_chimeric_seqs.py -m usearch61 -i Extreme_merged.fasta -r rdp_gold.fa -o uchimeM/
#: filter_fasta.py -f Extreme_merged.fasta -o Extreme_merged_nochim.fa -s uchimeM/chimeras.txt -n
#: pick_de_novo_otus.py -i Extreme_merged_nochim.fa -o qiimeM/
#: awk '{ print NF-1 }' qiimeM/uclust_picked_otus/Extreme_merged_nochim_otus.txt > qiimeM/uclust_picked_otus/count.txt

#: identify_chimeric_seqs.py -m usearch61 -i ExtremeFO_EE2.fasta -r rdp_gold.fa -o uchimeFO/
#: filter_fasta.py -f ExtremeFO_EE2.fasta -o ExtremeFO_EE2_nochim.fa -s uchimeFO/chimeras.txt -n
#: pick_de_novo_otus.py -i ExtremeFO_EE2_nochim.fa -o qiimeFO/
#: awk '{ print NF-1 }' qiimeFO/uclust_picked_otus/ExtremeFO_EE2_nochim_otus.txt > qiimeFO/uclust_picked_otus/count.txt

qiimeseqsFO <- readFasta("qiimeFO/rep_set/ExtremeFO_EE2_nochim_rep_set.fasta") # Lexically ordered!!
seqs <- as.character(sread(qiimeseqsFO))
indices <- sapply(strsplit(as.character(id(qiimeseqsFO)), " "), `[`, 1)
indices <- gsub("denovo", "", indices)
indices <- as.integer(indices)
ord <- order(indices, decreasing=FALSE)
seqs <- seqs[ord]
abunds <- read.table("qiimeFO/uclust_picked_otus/count.txt", header=FALSE) # Numerically ordered!!
abunds <- abunds[,1]
qiimeFO <- data.frame(sequence=seqs, abundance=abunds)

qiimeseqsM <- readFasta("qiimeM/rep_set/Extreme_merged_nochim_rep_set.fasta") # Lexically ordered!!
seqs <- as.character(sread(qiimeseqsM))
indices <- sapply(strsplit(as.character(id(qiimeseqsM)), " "), `[`, 1)
indices <- gsub("denovo", "", indices)
indices <- as.integer(indices)
ord <- order(indices, decreasing=FALSE)
seqs <- seqs[ord]
abunds <- read.table("qiimeM/uclust_picked_otus/count.txt", header=FALSE) # Numerically ordered!!
abunds <- abunds[,1]
qiimeM <- data.frame(sequence=seqs, abundance=abunds)
```

## Make joint data.frame with results from all the methods

Put together all output sequences in a single data.frame, and collapse those together that have no mismatches (i.e. have length differences only):
```{r}
# Remove singletons from mothur and QIIME
mothFO.noS <- mothFO[mothFO$abundance>1,]
qiimeFO.noS <- qiimeFO[qiimeFO$abundance>1,]

seqsFO <- unique(c(cFO$sequence, upFO$sequence, medFO$sequence, mothFO.noS$sequence, qiimeFO.noS$sequence))
allFO <- matrix(0, ncol=length(seqsFO), nrow=5)
colnames(allFO) <- seqsFO
rownames(allFO) <- c("dada", "uparse", "med", "mothur", "qiime")

allFO["dada", cFO$sequence] <- cFO$abundance
allFO["uparse", upFO$sequence] <- upFO$abundance
allFO["med", medFO$sequence] <- medFO$abundance
allFO["mothur", mothFO.noS$sequence] <- mothFO.noS$abundance
allFO["qiime", qiimeFO.noS$sequence] <- qiimeFO.noS$abundance
allFO <- collapseNoMismatch(allFO)
totFO.ex <- sum(derepFO$uniques)

# Remove singletons from mothur and QIIME
mothM.noS <- mothM[mothM$abundance>1,]
qiimeM.noS <- qiimeM[qiimeM$abundance>1,]

seqsM <- unique(c(merger$sequence, upM$sequence, medM$sequence, mothM.noS$sequence, qiimeM.noS$sequence))
allM <- matrix(0, ncol=length(seqsM), nrow=5)
colnames(allM) <- seqsM
rownames(allM) <- c("dada", "uparse", "med", "mothur", "qiime")
allM["dada", merger$sequence] <- merger$abundance
allM["uparse", upM$sequence] <- upM$abundance
allM["med", medM$sequence] <- medM$abundance
allM["mothur", mothM.noS$sequence] <- mothM.noS$abundance
allM["qiime", qiimeM.noS$sequence] <- qiimeM.noS$abundance
allM <- collapseNoMismatch(allM)
totM.ex <- sum(derepF$uniques)
```

Sanity check that imports were correct for each method:
```{r}
dfFO <- data.frame(t(allFO))
dfFO$sequence <- colnames(allFO)
dfM <- data.frame(t(allM))
dfM$sequence <- colnames(allM)

library(ggplot2)
ggplot(data=dfFO, aes(x=log10(dada), y=log10(uparse))) + geom_point()
ggplot(data=dfFO, aes(x=log10(dada), y=log10(med))) + geom_point()
# ggplot(data=dfFO, aes(x=log10(dada), y=log10(mothur))) + geom_point()
ggplot(data=dfFO, aes(x=log10(dada), y=log10(qiime))) + geom_point()

ggplot(data=dfM, aes(x=log10(dada), y=log10(uparse))) + geom_point()
ggplot(data=dfM, aes(x=log10(dada), y=log10(med))) + geom_point()
ggplot(data=dfM, aes(x=log10(dada), y=log10(mothur))) + geom_point()
ggplot(data=dfM, aes(x=log10(dada), y=log10(qiime))) + geom_point()
```

## Identify reference sequences

Read in the reference sequences and then find the hamming distance between all output sequences and those references:
```{r}
ref <- readFasta("ExtremeRefSeqs.fasta")
refSeqs <- as.character(sread(ref))
strain <- as.character(id(ref))

# Calculate hamming distance over the query sequence
evalDist <- Vectorize(function(query, ref, ...) {
  mmi <- dada2:::nweval(query, ref, ...) # match, mismatch, indel
  rval <- mmi[[2]] + mmi[[3]] # Usual hamming dist
  if(sum(mmi) < nchar(query)) { # query being ends-gapped out
    rval <- rval + nchar(query) - sum(mmi)
    # Add the query ends-gap overlap
  }
  return(rval)
})

dfFO.vs.ref <- outer(dfFO$sequence, refSeqs, evalDist, band=-1)
dfFO$refdist <- apply(dfFO.vs.ref, 1, min)

dfM.vs.ref <- outer(dfM$sequence, refSeqs, evalDist, band=-1)
dfM$refdist <- apply(dfM.vs.ref, 1, min)
```

Report the strain and sequence-level matches for each method (Forward-only):
```{r}
# Total reference sequences
sum(dfFO$refdist==0 & dfFO$dada > 0) # 26
sum(dfFO$refdist==0 & dfFO$uparse > 0) # 21
sum(dfFO$refdist==0 & dfFO$med > 0) # 16
sum(dfFO$refdist==0 & dfFO$mothur > 0) # 0
sum(dfFO$refdist==0 & dfFO$qiime > 0) # 20

# Total reference strains
dfFO.vs.strain <- t(rowsum(1*t(dfFO.vs.ref==0), strain)>0)
sum(colSums(dfFO.vs.strain[dfFO$dada>0,])>0) # 23
sum(colSums(dfFO.vs.strain[dfFO$uparse>0,])>0) # 21
sum(colSums(dfFO.vs.strain[dfFO$med>0,])>0) # 13
sum(colSums(dfFO.vs.strain[dfFO$mothur>0,])>0) # 0
sum(colSums(dfFO.vs.strain[dfFO$qiime>0,])>0) # 20
```

Report the strain and sequence-level matches for each method (Merged):
```{r}
# Total reference sequences
sum(dfM$refdist==0 & dfM$dada > 0) # 24
sum(dfM$refdist==0 & dfM$uparse > 0) # 18
sum(dfM$refdist==0 & dfM$med > 0) # 17
sum(dfM$refdist==0 & dfM$mothur > 0) # 23
sum(dfM$refdist==0 & dfM$qiime > 0) # 19

# Total reference strains
dfM.vs.strain <- t(rowsum(1*t(dfM.vs.ref==0), strain)>0)
sum(colSums(dfM.vs.strain[dfM$dada>0,])>0) # 21
sum(colSums(dfM.vs.strain[dfM$uparse>0,])>0) # 18
sum(colSums(dfM.vs.strain[dfM$med>0,])>0) # 14
sum(colSums(dfM.vs.strain[dfM$mothur>0,])>0) # 23
sum(colSums(dfM.vs.strain[dfM$qiime>0,])>0) # 19
```

## BLAST remainder to identify contaminants

Write fasta, then blastn against nt on [the NCBI website](http://blast.ncbi.nlm.nih.gov/blast/Blast.cgi):
```{r}
dfFO$id <- paste0("sq", dfFO$sequence)
unqsFO <- as.integer(dfFO$dada)
names(unqsFO) <- dfFO$sequence
uniquesToFasta(unqsFO, "unqsFO_ex.fasta", id=dfFO$id)
#### BLAST by hand against nt. Defaults. Megablast.
#### Save hit table (text) as unqsFO_hmp_blast.txt

dfM$id <- paste0("sq", dfM$sequence)
unqsM <- as.integer(dfM$dada)
names(unqsM) <- dfM$sequence
uniquesToFasta(unqsM, "unqsM_ex.fasta", id=dfM$id)
#### BLAST by hand against nt. Defaults. Megablast.
#### Save hit table (text) as unqsM_ex_blast.txt
```

Define functions to parse and compare to the downloaded hit tables:
```{r}
isHit100 <- function(clust, fn) {
  bb <- read.table(fn, comment.char="#", col.names=c("seqid", "subject", "identity", "coverage", "mismatches", "gaps", "seq_start", "seq_end", "sub_start", "sub_end", "e", "score"))
  bbHit100 <- bb[bb$identity == 100 & bb$coverage == nchar(clust[match(bb$seqid,clust$id),"sequence"]),]
  return(clust$id %in% bbHit100$seqid)
}

isOneOff <- function(clust, fn) {
  hit <- isHit100(clust, fn)
  bball <- read.table(fn, comment.char="#", col.names=c("seqid", "subject", "identity", "coverage", "mismatches", "gaps", "seq_start", "seq_end", "sub_start", "sub_end", "e", "score"))
  bb <- bball[bball$coverage == nchar(clust[match(bball$seqid,clust$id),"sequence"]),] # Only full length hits
  tab <- tapply(bb$identity, bb$seqid, max)
  tab <- tab[match(clust$id, names(tab))]
  seqlens <- nchar(clust$sequence)
  oneOff <- tab<100 & (abs(tab - 100.0*(seqlens-1)/seqlens) < 0.01)
  oneOff[is.na(oneOff)] <- FALSE # happens if no hits were full coverage
  names(oneOff) <- clust$id # Also drop the name to NA so fix here
  # Also get coverage=length-1 matches
  bb <- bball[bball$coverage == nchar(clust[match(bball$seqid,clust$id),"sequence"])-1,] # Full length-1 hits
  bb <- bb[bb$identity==100,]
  oneOff <- oneOff | clust$id %in% bb$seqid
  # Make sure not a hit
  oneOff[hit] <- FALSE
  return(oneOff)
}
```

Identify Exact and One Off hits to nt:
```{r}
dfFO$hit <- isHit100(dfFO, "unqsFO_ex_blast.txt")
dfFO$oo <- isOneOff(dfFO, "unqsFO_ex_blast.txt")

dfM$hit <- isHit100(dfM, "unqsM_ex_blast.txt")
dfM$oo <- isOneOff(dfM, "unqsM_ex_blast.txt")
```

Calculate the hamming distance to the nearest-larger-neighbor (i.e. more abundant output sequence):
```{r}
get_ham_nln <- function(unqs.in, band=16) {
  unqs.in <- getUniques(unqs.in)
  unqs <- sort(unqs.in, decreasing=TRUE)
  sqs <- names(unqs)
  rval <- sapply(seq(2,length(sqs)), function(i) min(nwhamming(sqs[[i]], sqs[1:i-1], band=band) ))
  rval <- c(NA, rval)
  rval[match(names(unqs.in), names(unqs))] # Back to input ordering
}

dfFO$dada_ham_nln <- as.integer(NA)
dfFO$dada_ham_nln[dfFO$dada>0] <- get_ham_nln(data.frame(sequence=dfFO$sequence[dfFO$dada>0], abundance=dfFO$dada[dfFO$dada>0]))
dfFO$uparse_ham_nln <- as.integer(NA)
dfFO$uparse_ham_nln[dfFO$uparse>0] <- get_ham_nln(data.frame(sequence=dfFO$sequence[dfFO$uparse>0], abundance=dfFO$uparse[dfFO$uparse>0]))
dfFO$med_ham_nln <- as.integer(NA)
dfFO$med_ham_nln[dfFO$med>0] <- get_ham_nln(data.frame(sequence=dfFO$sequence[dfFO$med>0], abundance=dfFO$med[dfFO$med>0]))
dfFO$mothur_ham_nln <- as.integer(NA)
# dfFO$mothur_ham_nln[dfFO$mothur>0] <- get_ham_nln(data.frame(sequence=dfFO$sequence[dfFO$mothur>0], abundance=dfFO$mothur[dfFO$mothur>0]))
dfFO$qiime_ham_nln <- as.integer(NA)
dfFO$qiime_ham_nln[dfFO$qiime>0] <- get_ham_nln(data.frame(sequence=dfFO$sequence[dfFO$qiime>0], abundance=dfFO$qiime[dfFO$qiime>0]))

dfM$dada_ham_nln <- as.integer(NA)
dfM$dada_ham_nln[dfM$dada>0] <- get_ham_nln(data.frame(sequence=dfM$sequence[dfM$dada>0], abundance=dfM$dada[dfM$dada>0]))
dfM$uparse_ham_nln <- as.integer(NA)
dfM$uparse_ham_nln[dfM$uparse>0] <- get_ham_nln(data.frame(sequence=dfM$sequence[dfM$uparse>0], abundance=dfM$uparse[dfM$uparse>0]))
dfM$med_ham_nln <- as.integer(NA)
dfM$med_ham_nln[dfM$med>0] <- get_ham_nln(data.frame(sequence=dfM$sequence[dfM$med>0], abundance=dfM$med[dfM$med>0]))
dfM$mothur_ham_nln <- as.integer(NA)
dfM$mothur_ham_nln[dfM$mothur>0] <- get_ham_nln(data.frame(sequence=dfM$sequence[dfM$mothur>0], abundance=dfM$mothur[dfM$mothur>0]))
dfM$qiime_ham_nln <- as.integer(NA)
dfM$qiime_ham_nln[dfM$qiime>0] <- get_ham_nln(data.frame(sequence=dfM$sequence[dfM$qiime>0], abundance=dfM$qiime[dfM$qiime>0]))
```

## Assign and table accuracy for each method

Define and assign accuracy classification:
```{r}
getAccuracy <- function(df) {
  acc <- rep(is.character(NA), nrow(df))
  acc[df$hit] <- "Exact"
  acc[df$oo] <- "One Off"
  acc[!df$oo & !df$hit] <- "Other"
  acc[df$refdist==0] <- "Reference"
  acc[df$refdist==1] <- "One Off"
  acc <- factor(acc, levels=c("Reference", "Exact", "One Off", "Other"))
  acc
}
dfFO$Accuracy <- getAccuracy(dfFO)
dfM$Accuracy <- getAccuracy(dfM)
```

Report out the accuracy tables for each method (Table 1):
```{r}
table(dfFO$Accuracy[dfFO$dada>0])
table(dfFO$Accuracy[dfFO$uparse>0])
table(dfFO$Accuracy[dfFO$med>0])
table(dfFO$Accuracy[dfFO$mothur>0])
table(dfFO$Accuracy[dfFO$qiime>0])

table(dfM$Accuracy[dfM$dada>0])
table(dfM$Accuracy[dfM$uparse>0])
table(dfM$Accuracy[dfM$med>0])
table(dfM$Accuracy[dfM$mothur>0])
table(dfM$Accuracy[dfM$qiime>0])
```

## Make comparative plots

Classify output sequences of the non-UPARSE methods relative to UPARSE output:
```{r}
dvuScale <- scale_color_manual(name="Vs. UPARSE", values=c("Same"="black", "Added"="#0099FF", "Lost"="grey70"))
dfM$DvU <- "Same"
dfM$DvU[dfM$uparse==0 & dfM$dada>0] <- "Added"
dfM$DvU[dfM$uparse>0 & dfM$dada==0] <- "Lost"
dfM$DvU[dfM$uparse==0 & dfM$dada==0] <- "N/A"

mvuScale <- scale_color_manual(name="Vs. UPARSE", values=c("Same"="black", "Added"="green", "Lost"="grey70"))
dfM$MvU <- "Same"
dfM$MvU[dfM$uparse==0 & dfM$med>0] <- "Added"
dfM$MvU[dfM$uparse>0 & dfM$med==0] <- "Lost"
dfM$MvU[dfM$uparse==0 & dfM$med==0] <- "N/A"

hvuScale <- scale_color_manual(name="Vs. UPARSE", values=c("Same"="black", "Added"="orange", "Lost"="grey70"))
dfM$HvU <- "Same"
dfM$HvU[dfM$uparse==0 & dfM$mothur>0] <- "Added"
dfM$HvU[dfM$uparse>0 & dfM$mothur==0] <- "Lost"
dfM$HvU[dfM$uparse==0 & dfM$mothur==0] <- "N/A"

qvuScale <- scale_color_manual(name="Vs. UPARSE", values=c("Same"="black", "Added"="red", "Lost"="grey70"))
dfM$QvU <- "Same"
dfM$QvU[dfM$uparse==0 & dfM$qiime>0] <- "Added"
dfM$QvU[dfM$uparse>0 & dfM$qiime==0] <- "Lost"
dfM$QvU[dfM$uparse==0 & dfM$qiime==0] <- "N/A"

dfFO$DvU <- "Same"
dfFO$DvU[dfFO$uparse==0 & dfFO$dada>0] <- "Added"
dfFO$DvU[dfFO$uparse>0 & dfFO$dada==0] <- "Lost"
dfFO$DvU[dfFO$uparse==0 & dfFO$dada==0] <- "N/A"

dfFO$MvU <- "Same"
dfFO$MvU[dfFO$uparse==0 & dfFO$med>0] <- "Added"
dfFO$MvU[dfFO$uparse>0 & dfFO$med==0] <- "Lost"
dfFO$MvU[dfFO$uparse==0 & dfFO$med==0] <- "N/A"

dfFO$HvU <- "Same"
dfFO$HvU[dfFO$uparse==0 & dfFO$mothur>0] <- "Added"
dfFO$HvU[dfFO$uparse>0 & dfFO$mothur==0] <- "Lost"
dfFO$HvU[dfFO$uparse==0 & dfFO$mothur==0] <- "N/A"

dfFO$QvU <- "Same"
dfFO$QvU[dfFO$uparse==0 & dfFO$qiime>0] <- "Added"
dfFO$QvU[dfFO$uparse>0 & dfFO$qiime==0] <- "Lost"
dfFO$QvU[dfFO$uparse==0 & dfFO$qiime==0] <- "N/A"
```

Define plotting parameters:
```{r}
library(ggplot2)
library(grid)
library(gridExtra)

scl.y <- scale_y_log10(limits=c(10^-6, 10^-0.5))
scl.x <- scale_x_log10(limits=c(1, 90))
thm <- theme(plot.margin=rep(unit(0, "in"),4), panel.grid=element_blank(), legend.key=element_blank())
accScale <- scale_shape_manual(name="Accuracy", values=c("Reference"=0, "Exact"=2, "One Off"=4, "Other"=8))
lab.x <- xlab("Hamming (Log-scale)")
lab.y <- ylab("Frequency (Log-scale)")
```

Make display plots for the Extreme merged reads (Figure 1 and Figure S7):
```{r warning=FALSE}
m1 <- ggplot(data=dfM[dfM$uparse>0,], aes(x=uparse_ham_nln, y=uparse/totM.ex, shape=Accuracy))
m1 <- m1 + geom_point(size=3)
m1 <- m1 + accScale + theme_bw() + ggtitle("UPARSE")
m1 <- m1 + scl.y + scl.x + thm + lab.x + lab.y
m1

m2 <- ggplot(data=dfM[dfM$dada>0 | dfM$uparse>0,], aes(x=dada_ham_nln, y=dada/totM.ex, shape=Accuracy, color=DvU))
m2 <- m2 + geom_point(size=3)
m2 <- m2 + geom_point(data=dfM[dfM$uparse>0 & dfM$dada==0,], aes(x=uparse_ham_nln, y=uparse/totM.ex), size=2, show.legend=FALSE)
m2 <- m2 + accScale + dvuScale + theme_bw() + ggtitle("DADA2")
m2 <- m2 + scl.y + scl.x + thm + lab.x + lab.y
m2 <- m2 + geom_vline(xintercept=0.03*nchar(dfM$sequence[[1]]), linetype="dashed", color="grey25")
m2
#ggsave("~/Desktop/Illumina/MB/dvuM.png", m2 + ggtitle("Balanced: Merged Reads"))
#saveRDS(totM.ex, file="~/Desktop/DADA2Final/fig/ex_tot.rds")
#saveRDS(m2, file="~/Desktop/DADA2Final/fig/ex_m2.rds")

m3 <- ggplot(data=dfM[dfM$med>0 | dfM$uparse>0,], aes(x=med_ham_nln, y=med/totM.ex, shape=Accuracy, color=MvU))
m3 <- m3 + geom_point(size=3)
m3 <- m3 + geom_point(data=dfM[dfM$uparse>0 & dfM$med==0,], aes(x=uparse_ham_nln, y=uparse/totM.ex), size=2, show.legend=FALSE)
m3 <- m3 + accScale + mvuScale + theme_bw() + ggtitle("MED")
m3 <- m3 + scl.y + scl.x + thm + lab.x + lab.y
m3 <- m3 + geom_vline(xintercept=0.03*nchar(dfM$sequence[[1]]), linetype="dashed", color="grey25")
m3

m4 <- ggplot(data=dfM[dfM$mothur>0 | dfM$uparse>0,], aes(x=mothur_ham_nln, y=mothur/totM.ex, shape=Accuracy, color=HvU))
m4 <- m4 + geom_point(size=3)
m4 <- m4 + geom_point(data=dfM[dfM$uparse>0 & dfM$mothur==0,], aes(x=uparse_ham_nln, y=uparse/totM.ex), size=2, show.legend=FALSE)
m4 <- m4 + accScale + hvuScale + theme_bw() + ggtitle("Mothur")
m4 <- m4 + scl.y + scl.x + thm + lab.x + lab.y
m4 <- m4 + geom_vline(xintercept=0.03*nchar(dfM$sequence[[1]]), linetype="dashed", color="grey25")
m4

m5 <- ggplot(data=dfM[dfM$qiime>0 | dfM$uparse>0,], aes(x=qiime_ham_nln, y=qiime/totM.ex, shape=Accuracy, color=QvU))
m5 <- m5 + geom_point(size=3)
m5 <- m5 + geom_point(data=dfM[dfM$uparse>0 & dfM$qiime==0,], aes(x=uparse_ham_nln, y=uparse/totM.ex), size=2, show.legend=FALSE)
m5 <- m5 + accScale + qvuScale + theme_bw() + ggtitle("QIIME")
m5 <- m5 + scl.y + scl.x + thm + lab.x + lab.y
m5 <- m5 + geom_vline(xintercept=0.03*nchar(dfM$sequence[[1]]), linetype="dashed", color="grey25")
m5

require(gridExtra)
upper <- arrangeGrob(m1, m2, ncol=2)
lower <- arrangeGrob(m3, m4, m5, ncol=3)
supfigM <- arrangeGrob(upper, lower, ncol=1, heights=c(3,2))
plot(supfigM)
# ggsave("Fig_ex_allM.pdf", plot=supfigM, width=14, height=8, units="in", useDingbats=F)
```

Make display plots for the Extreme forward-only reads (Figure S4):
```{r warning=FALSE}
fo1 <- ggplot(data=dfFO[dfFO$uparse>0,], aes(x=uparse_ham_nln, y=uparse/totFO.ex, shape=Accuracy))
fo1 <- fo1 + geom_point(size=3)
fo1 <- fo1 + accScale + theme_bw() + ggtitle("UPARSE")
fo1 <- fo1 + scl.y + scl.x + thm + lab.x + lab.y
fo1

fo2 <- ggplot(data=dfFO[dfFO$dada>0 | dfFO$uparse>0,], aes(x=dada_ham_nln, y=dada/totFO.ex, shape=Accuracy, color=DvU))
fo2 <- fo2 + geom_point(size=3)
fo2 <- fo2 + geom_point(data=dfFO[dfFO$uparse>0 & dfFO$dada==0,], aes(x=uparse_ham_nln, y=uparse/totFO.ex), size=2, show.legend=FALSE)
fo2 <- fo2 + accScale + dvuScale + theme_bw() + ggtitle("DADA2")
fo2 <- fo2 + scl.y + scl.x + thm + lab.x + lab.y
fo2 <- fo2 + geom_vline(xintercept=0.03*nchar(dfFO$sequence[[1]]), linetype="dashed", color="grey25")
fo2

fo3 <- ggplot(data=dfFO[dfFO$med>0 | dfFO$uparse>0,], aes(x=med_ham_nln, y=med/totFO.ex, shape=Accuracy, color=MvU))
fo3 <- fo3 + geom_point(size=3)
fo3 <- fo3 + geom_point(data=dfFO[dfFO$uparse>0 & dfFO$med==0,], aes(x=uparse_ham_nln, y=uparse/totFO.ex), size=2, show.legend=FALSE)
fo3 <- fo3 + accScale + mvuScale + theme_bw() + ggtitle("MED")
fo3 <- fo3 + scl.y + scl.x + thm + lab.x + lab.y
fo3 <- fo3 + geom_vline(xintercept=0.03*nchar(dfFO$sequence[[1]]), linetype="dashed", color="grey25")
fo3

fo4 <- ggplot(data=dfFO[dfFO$mothur>0 | dfFO$uparse>0,], aes(x=mothur_ham_nln, y=mothur/totFO.ex, shape=Accuracy, color=HvU))
fo4 <- fo4 + geom_point(size=3)
fo4 <- fo4 + geom_point(data=dfFO[dfFO$uparse>0 & dfFO$mothur==0,], aes(x=uparse_ham_nln, y=uparse/totFO.ex), size=2, show.legend=FALSE)
fo4 <- fo4 + accScale + hvuScale + theme_bw() + ggtitle("Mothur")
fo4 <- fo4 + scl.y + scl.x + thm + lab.x + lab.y
fo4 <- fo4 + geom_vline(xintercept=0.03*nchar(dfFO$sequence[[1]]), linetype="dashed", color="grey25")
fo4

fo5 <- ggplot(data=dfFO[dfFO$qiime>0 | dfFO$uparse>0,], aes(x=qiime_ham_nln, y=qiime/totFO.ex, shape=Accuracy, color=QvU))
fo5 <- fo5 + geom_point(size=3)
fo5 <- fo5 + geom_point(data=dfFO[dfFO$uparse>0 & dfFO$qiime==0,], aes(x=uparse_ham_nln, y=uparse/totFO.ex), size=2, show.legend=FALSE)
fo5 <- fo5 + accScale + qvuScale + theme_bw() + ggtitle("QIIME")
fo5 <- fo5 + scl.y + scl.x + thm + lab.x + lab.y
fo5 <- fo5 + geom_vline(xintercept=0.03*nchar(dfFO$sequence[[1]]), linetype="dashed", color="grey25")
fo5

require(gridExtra)
upper <- arrangeGrob(fo1, fo2, ncol=2)
lower <- arrangeGrob(fo3, fo4, fo5, ncol=3)
supfigFO <- arrangeGrob(upper, lower, ncol=1, heights=c(3,2))
plot(supfigFO)
# ggsave("Fig_ex_allFO.pdf", supfigFO, width=14, height=8, units="in", useDingbats=F)
```

## Identify chimeras in the Other output sequences

Using UPARSE-REF to classify whether Other sequences are chimeric:
```{r}
dfFO$abundance <- 1
uniquesToFasta(dfFO[dfFO$Accuracy == "Other", ], "dfFO_other.fa", id=which(dfFO$Accuracy == "Other"))
dfFO$abundance <- NULL
#: usearch -uparse_ref dfFO_other.fa -db ExtremeRefSeqs.fasta -strand plus -uparse_break -3 -uparseout uref_dfFO.up
# Note that uparse_ref does not maintain input sequence order in its output
foo <- read.table("uref_dfFO.up")
up.chim <- ((foo$V2 == "chimera") & (foo$V4 > 99)) # UPARSE paper criteria
sqi <- foo$V1
dfFO$refChim <- NA
dfFO$refChim[sqi] <- up.chim

dfM$abundance <- 1
uniquesToFasta(dfM[dfM$Accuracy == "Other", ], "dfM_other.fa", id=which(dfM$Accuracy == "Other"))
dfM$abundance <- NULL
#: usearch -uparse_ref dfM_other.fa -db ExtremeRefSeqs.fasta -strand plus -uparse_break -3 -uparseout uref_dfM.up
# Note that uparse_ref does not maintain input sequence order in its output
foo <- read.table("uref_dfM.up")
up.chim <- ((foo$V2 == "chimera") & (foo$V4 > 99)) # UPARSE paper criteria
sqi <- foo$V1
dfM$refChim <- NA
dfM$refChim[sqi] <- up.chim
```

Output the table of chimeric classifications (Table S3):
```{r}
table(dfFO[dfFO$Accuracy == "Other" & dfFO$dada>0, "refChim"])
table(dfFO[dfFO$Accuracy == "Other" & dfFO$uparse>0, "refChim"])
table(dfFO[dfFO$Accuracy == "Other" & dfFO$med>0, "refChim"])
table(dfFO[dfFO$Accuracy == "Other" & dfFO$mothur>0, "refChim"])
table(dfFO[dfFO$Accuracy == "Other" & dfFO$qiime>0, "refChim"])

table(dfM[dfM$Accuracy == "Other" & dfM$dada>0, "refChim"])
table(dfM[dfM$Accuracy == "Other" & dfM$uparse>0, "refChim"])
table(dfM[dfM$Accuracy == "Other" & dfM$med>0, "refChim"])
table(dfM[dfM$Accuracy == "Other" & dfM$mothur>0, "refChim"])
table(dfM[dfM$Accuracy == "Other" & dfM$qiime>0, "refChim"])
```




